{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from heapq import nlargest\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\", quiet=True)\n",
    "nltk.download(\"stopwords\", quiet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сумаризація тексту за допомогою `nltk`\n",
    "\n",
    "1. [Суммаризация текста: подходы, алгоритмы, рекомендации и перспективы](https://habr.com/ru/articles/514540/)\n",
    "\n",
    "Скористаємось алгоритмом екстрактивної сумаризації запропонованим в статті [1]\n",
    "\n",
    "- Розбиття вхідного тексту на окремі речення \n",
    "- Переведення речення у цифрове представлення (вектор).\n",
    "- Обчислення і збереження в матриці подібності подібності між векторами речень.\n",
    "- Перетворення отриманої матриці на граф із реченнями у вигляді вершин і оцінками подібності у вигляді ребер для обчислення рангу речень.\n",
    "- Вибір пропозицій з найвищою оцінкою для підсумкового резюме."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Створюємо теку з стоп-словами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Перевіряємо наявність папки corpora/stopwords у каталозі nltk_data\n",
    "nltk_data_path = nltk.data.path[0]\n",
    "stopwords_path = os.path.join(nltk_data_path, \"corpora\", \"stopwords\")\n",
    "if not os.path.exists(stopwords_path):\n",
    "    os.makedirs(stopwords_path)\n",
    "\n",
    "\n",
    "# Завантажуємо стоп-слова для української мови та зберігаємо у файл\n",
    "url = \"https://raw.githubusercontent.com/skupriienko/Ukrainian-Stopwords/master/stopwords_ua.txt\"\n",
    "r = requests.get(url)\n",
    "\n",
    "with open(os.path.join(stopwords_path, \"english\"), \"wb\") as f:\n",
    "    f.write(r.content)\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Завантажуємо текст з файлу у змінну"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"text_en.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визначаємо функції\n",
    "\n",
    "1. [Cosine Similarity and Cosine Distance](https://medium.com/geekculture/cosine-similarity-and-cosine-distance-48eed889a5c4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_similarity(sent1, sent2, stopwords=None):\n",
    "    \"\"\"\n",
    "    Функція вимірює схожість між двома реченнями. Використовується косинусна\n",
    "    відстань між векторами, що представляють слова в реченнях. Вона також\n",
    "    враховує стоп-слова.\n",
    "    \"\"\"\n",
    "    if stopwords is None:\n",
    "        stopwords = set()\n",
    "\n",
    "    # Токенізуємо речення та видаляємо стоп-слова\n",
    "\n",
    "    words1 = [\n",
    "        word.lower()\n",
    "        for word in word_tokenize(sent1)\n",
    "        if word.isalnum() and word.lower() not in stopwords\n",
    "    ]  # створюємо список слів (без стоп-слів) із першого речення\n",
    "    words2 = [\n",
    "        word.lower()\n",
    "        for word in word_tokenize(sent2)\n",
    "        if word.isalnum() and word.lower() not in stopwords\n",
    "    ]  # створюємо список слів (без стоп-слів) із першого речення\n",
    "\n",
    "    all_words = list(\n",
    "        set(words1 + words2)\n",
    "    )  # створюємо список унікальних слів з двох речень\n",
    "\n",
    "    # Створюємо вектори типу компонентами яких є  одиниці та нулі\n",
    "    # якщо слово є в речення, то ставимо 1, інакше 0\n",
    "    # Отримуємо щось таке [1, 0, 0, 1, ...]\n",
    "    vector1 = [1 if word in words1 else 0 for word in all_words]\n",
    "    vector2 = [1 if word in words2 else 0 for word in all_words]\n",
    "\n",
    "    # розраховуємо косинусну відстань між двома векторами\n",
    "\n",
    "    return 1 - cosine_distance(vector1, vector2)\n",
    "\n",
    "\n",
    "def build_similarity_matrix(sentences, stop_words):\n",
    "    \"\"\"\n",
    "    Функція будує матрицю схожості між усіма парами речень у тексті.\n",
    "    \"\"\"\n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    "\n",
    "    for i in range(len(sentences)):\n",
    "        for j in range(len(sentences)):\n",
    "            if i != j:\n",
    "                similarity_matrix[i][j] = sentence_similarity(\n",
    "                    sentences[i], sentences[j], stop_words\n",
    "                )\n",
    "\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "def generate_summary(text, num_sentences=3, stop_words=stop_words):\n",
    "    \"\"\"\n",
    "    Функція створює короткий зміст тексту.\n",
    "\n",
    "    Алгоритм роботи:\n",
    "\n",
    "    1. Читаємо речення із тексту і потім будуємо матрицю схожості.\n",
    "    2. Розраховуємо суму схожості для кожного речення.\n",
    "    3. Використовуємо nlargest для вибору топ N речень за порядком зменшення схожості.\n",
    "    4. Об'єднуємо вибрані речення в один рядок.\n",
    "\n",
    "    \"\"\"\n",
    "    summarize_text = []\n",
    "\n",
    "    sentences = sent_tokenize(text)  # Токенізуємо текст\n",
    "\n",
    "    sentence_similarity_matrix = build_similarity_matrix(sentences, stop_words)\n",
    "\n",
    "    sentence_similarity_scores = np.array(\n",
    "        [sum(row) for row in sentence_similarity_matrix]\n",
    "    )\n",
    "\n",
    "    # Використовуємо nlargest для вибору топ N речень за порядком зменшення схожості\n",
    "    top_sentences_indices = nlargest(\n",
    "        num_sentences,\n",
    "        range(len(sentence_similarity_scores)),\n",
    "        key=sentence_similarity_scores.__getitem__,\n",
    "    )\n",
    "\n",
    "    # Формуємо короткий зміст з вибраних речень\n",
    "    for i in top_sentences_indices:\n",
    "        summarize_text.append(sentences[i])\n",
    "\n",
    "    return \" \".join(summarize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Записуємо анотований текст до файлу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sentences = 3\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "summary = generate_summary(text, num_sentences, stop_words)\n",
    "with open(\"summary_ua.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Висновки\n",
    "\n",
    "Отже, ми маємо "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The Orbiter Discovery, OV-103, is considered eligible for listing in the National Register of Historic Places (NRHP) in the context of the U.S. Space Shuttle Program (1969-2011) under Criterion A in the areas of Space Exploration and Transportation and under Criterion C in the area of Engineering. Because it has achieved significance within the past fifty years, Criteria Consideration G applies. Under Criterion A, Discovery is significant as the oldest of the three extant orbiter vehicles constructed for the Space Shuttle Program (SSP), the longest running American space program to date; she was the third of five orbiters built by NASA. Unlike the Mercury, Gemini, and Apollo programs, the SSP’s emphasis was on cost effectiveness and reusability, and eventually the construction of a space station. Including her maiden voyage (launched August 30, 1984), Discovery flew to space thirty-nine times, more than any of the other four orbiters; she was also the first orbiter to fly twenty missions. She had the honor of being chosen as the Return to Flight vehicle after both the Challenger and Columbia accidents. Discovery was the first shuttle to fly with the redesigned SRBs, a result of the Challenger accident, and the first shuttle to fly with the Phase II and Block I SSME. Discovery also carried the Hubble Space Telescope to orbit and performed two of the five servicing missions to the observatory. She flew the first and last dedicated Department of Defense (DoD) missions, as well as the first unclassified defense-related mission. In addition, Discovery was vital to the construction of the International Space Station (ISS); she flew thirteen of the thirty-seven total missions flown to the station by a U.S. Space Shuttle. She was the first orbiter to dock to the ISS, and the first to perform an exchange of a resident crew. Under Criterion C, Discovery is significant as a feat of engineering. According to Wayne Hale, a flight director from Johnson Space Center, the Space Shuttle orbiter represents a “huge technological leap from expendable rockets and capsules to a reusable, winged, hypersonic, cargo-carrying spacecraft.” Although her base structure followed a conventional aircraft design, she used advanced materials that both minimized her weight for cargo-carrying purposes and featured low thermal expansion ratios, which provided a stable base for her Thermal Protection System (TPS) materials. The Space Shuttle orbiter also featured the first reusable TPS; all previous spaceflight vehicles had a single-use, ablative heat shield. Other notable engineering achievements of the orbiter included the first reusable orbital propulsion system, and the first two-fault-tolerant Integrated Avionics System. As Hale stated, the Space Shuttle remains “the largest, fastest, winged hypersonic aircraft in history,” having regularly flown at twenty-five times the speed of sound."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "та [його анотацію](./summary_ua.txt):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "She was the first orbiter to dock to the ISS, and the first to perform an exchange of a resident crew. In addition, Discovery was vital to the construction of the International Space Station (ISS); she flew thirteen of the thirty-seven total missions flown to the station by a U.S. Space Shuttle. Under Criterion A, Discovery is significant as the oldest of the three extant orbiter vehicles constructed for the Space Shuttle Program (SSP), the longest running American space program to date; she was the third of five orbiters built by NASA."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Довжина вихідного тексту: 2906\n",
      "Довжина анотації: 542\n"
     ]
    }
   ],
   "source": [
    "print(f\"Довжина вихідного тексту: {len(text)}\")\n",
    "print(f\"Довжина анотації: {len(summary)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Згенероване NLTK summary інформацію про кількість польотів \"Діскавері\", важливі моменти в його історії, такі як перший політ та участь у будівництві МКС. Однак, воно вигдядає якось не дуже напоіненим.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
